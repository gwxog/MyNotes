# 工作内容

## 1 分辨正常、异常数据和设备（2021-1-6）

2021-1-6 领到课题

2021-1-13 分析报告写完, 要来数据



# spark

## 1 spark单机测试配置



## 2 sparkSQL

### 2.1 数据库连接

#### 2.1.1 sqlite

```scala
val jdbcRDD: JdbcRDD[SensorDataGps] = new JdbcRDD(
      sc,
      conn,  // conn: () => Connection
      sql,
      lowBound, upBound, numPartitions,
      rs => {
        val id: Int = rs.getInt(1)
        val car_no: String = rs.getString(2)
        val direction: Int = rs.getInt(3)
        val enable_level: String = rs.getString(4)
        val grid_key: String = rs.getString(5)
        val group: Int = rs.getInt(6)
        val lat: Double = rs.getDouble(7)
        val lng: Double = rs.getDouble(8)
        val loc_time: Int = rs.getInt(9)
        val pm10: Double = rs.getDouble(10)
        val pm25: Double = rs.getDouble(11)
        val satellite_num: Int = rs.getInt(12)
        val sn: String = rs.getString(13)
        val speed: Double = rs.getDouble(14)
        val status: Int = rs.getInt(15)
        val time: String = rs.getString(16)
        val co: Double = rs.getDouble(17)
        val co_f: Double = rs.getDouble(18)
        val so2_f: String = rs.getString(19)
        val no_f: Double = rs.getDouble(20)
        val no2: Double = rs.getDouble(21)
        val o3: String = rs.getString(22)
        val tvoc: Double = rs.getDouble(23)
        val content: String = rs.getString(24)
        SensorDataGps(id, car_no, direction, enable_level, grid_key, group, lat, lng, loc_time, pm10, pm25, satellite_num, sn, speed, status, time, co, co_f, so2_f, no_f, no2, o3, tvoc, content)
      }
    )
```

### 2.2 spark写入csv

应用Hadoop环境时，如果报错

```
org.apache.hadoop.io.nativeio.NativeIO$Windows.createFileWithMode0
```

则将windows系统下的hadoop的bin目录中和Windows/System23目录中的hadoop.dll文件删除即可

2.3 spark连接hdfs上sqlite数据库路径写法

```scala
val url = "jdbc:sqlite::resource:hdfs://node01:8020/SparkData/sensordata/sensordatagps_2020-12-10_00-00-00_1.db"
```

|注意：此处要加`:resource:`

# hadoop

## 1 配置Hadoop本地开发环境

解压hadoop-2.7.5

添加环境变量HADOOP_HOME和CLASSPATH，以及bin

将bin下的hadoop.dll放到c://Windows/System32下

## 2 hadoop的安全模式

![image-20210102234146180](img/Spark工作笔记/image-20210102234146180.png)

此时，禁止写入和删除hdfs文件，需要离开安全模式才可以

![image-20210102234313713](img/Spark工作笔记/image-20210102234313713.png)

![image-20210103000017569](img/Spark工作笔记/image-20210103000017569.png)

## 3 yarn资源释放

```shell
#查看当前yarn资源占用
yarn application -list
#kill应用
yarn application -kill 应用id
```

# java

1 SimpleDateFormat高并发异常

```java
java.lang.NumberFormatException: For input string: ""
```

SimpleDateFormat(下面简称sdf)类内部有一个Calendar对象引用,它用来储存和这个sdf相关的日期信息,例如sdf.parse(dateStr), sdf.format(date) 诸如此类的方法参数传入的日期相关String, Date等等, 都是交友Calendar引用来储存的.这样就会导致一个问题,如果你的sdf是个static的, 那么多个thread 之间就会共享这个sdf, 同时也是共享这个Calendar引用

# flink

## 1 双流join、connection和CoProcessFunction





# kafka

## 1 Kafak JDBC连接







# docker

## 1 进入容器, 报错WARNING: IPv4...

![image-20210105181641133](img/工作笔记/image-20210105181641133.png)

没有开启转发,网桥配置完后，需要开启转发，不然容器启动后，就会没有网络，配置`/etc/sysctl.conf`,添加`net.ipv4.ip_forward=1`

```shell
vim /etc/sysctl.conf

#配置转发
net.ipv4.ip_forward=1

#重启服务，让配置生效
systemctl restart network

#查看是否成功,如果返回为“net.ipv4.ip_forward = 1”则表示成功
sysctl net.ipv4.ip_forward
```

检查容器是否正常访问网络

```shell
#重启docker服务
service docker restart 

#查看运行过的容器
docker ps -a

#启动gitlab 容器
docker start gitblab2 

#进入gitlab容器
docker attach gitlab2

#获取百度信息
curl baidu.com
```

![这里写图片描述](img/工作笔记/20171020150519615.png)

# python

## 1 绘图

### 1.1 时序图

- pandas.date_range()用法

  date_range()是pandas中常用的函数，用于生成一个固定频率的DatetimeIndex时间索引。原型：

  ```python
  date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)
  
  - 常用参数为start、end、periods、freq。
    start：指定生成时间序列的开始时间
    end：指定生成时间序列的结束时间
    periods：指定生成时间序列的数量
    freq：生成频率，默认‘D’，可以是’H’、‘D’、‘M’、‘5H’、‘10D’、…
    normalize：若参数为True表示将start、end参数值正则化到午夜时间戳
    name：生成时间索引对象的名称，取值为string或None
    还可以根据closed参数选择是否包含开始和结束时间，left包含开始时间，不包含结束时间，right与之相反。默认同时包含开始时间和结束时间。
      
  函数调用时至少要指定参数start、end、periods中的两个。
  ```

  




## 2 dask



## 3 多进程



## 4 python项目部署Linux

### 1.安装相应的编译工具

在root用户下(不要用普通用户,麻烦),全部复制粘贴过去,一次性安装即可.

```
yum -y groupinstall "Development tools"
yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel
yum install -y libffi-devel zlib1g-dev
yum install zlib* -y
```

### 2.下载安装包

```
wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tar.xz
```

### 3.创建编译安装目录

```
mkdir /export/servers/python3.6.9 
```

### 4.解压

```
tar -xvJf  Python-3.6.9.tar.xz -C /export/servers
```

### 5.安装

```shell
cd /export/servers/Python-3.6.9
./configure --prefix=/export/servers/python3.6.9 --enable-optimizations --with-ssl 
#第一个指定安装的路径,不指定的话,安装过程中可能软件所需要的文件复制到其他不同目录,删除软件很不方便,复制软件也不方便.
#第二个可以提高python10%-20%代码运行速度.
#第三个是为了安装pip需要用到ssl,后面报错会有提到.
make && make install
```

### 6.创建软链接

```
ln -s /usr/local/python3/bin/python3 /usr/local/bin/python3
ln -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3
```

### 7.验证是否成功

```
python3 -V
pip3 -V
```

### 8.修改pip安装源

修改系统pip安装源
在家目录下新建`.pip`文件夹,进入文件夹新建文件`pip.conf`之后写入相应镜像网站地址

```
cd ~
mkdir .pip
cd .pip
vim pip.conf

#进入后添加以下内容,保存退出.
[global]
index-url = https://mirrors.aliyun.com/pypi/simple
```

修改pipenv安装源
在自己的虚拟环境中找到`Pipfile`文件,将其中的`url = "https://pypi.org/simple"`修改为你需要的国内镜像,如`https://mirrors.aliyun.com/pypi/simple/`

```
[root@localhost myproject]# vim Pipfile 


[[source]]
name = "pypi"
url = "https://pypi.org/simple" # 改为url = "https://mirrors.aliyun.com/pypi/simple/"
verify_ssl = true

[dev-packages] #这里是开发环境专属包,使用pipenv install --dev package来安装专属开发环境的包

[packages] # 全部环境的通用包,安装在这里.

[requires]
python_version = "3.7"
```

### 9.将本地开发环境的依赖项目生成清单文件

(1).在本地的开发环境中，env下执行：

```
pip3 freeze >requirements.txt
```

清单文件将会生成在当前项目目录下，内容如下所示

```
certifi==2018.4.16chardet==3.0.4idna==2.7requests==2.19.1urllib3==1.23
```

将生成后的文件上传到linux服务器

(2).将Python项目上传到服务器

```
#略...
```

### 10.在linux服务器上为项目创建虚拟环境，并安装项目所需的依赖

(1).切换到pip3所在的目录 /usr/local/python/bin，执行以下命令

```shell
# 安装虚拟环境
pip3 install virtualenv
# 创建虚拟环境 ENV
virtualenv ENV
# 切换到虚拟环境所在的目录
cd ENV
# 启用虚拟环境
source ./bin/activate
# 安装依赖清单里的库
pip3 install -r requirements.txt
# 列出当前虚拟环境所安装的依赖库
pip3 list
```

### 11.添加自定义系统服务（很重要）

```
# 这样的命令在ssh终端退出后，python进程也会被杀掉python xxx.py &
```

需要创建一个自定义的系统服务，来保证python程序能够在后台运行。

(1).创建系统服务

```
vim /usr/lib/systemd/system/robot.service
```

内容如下：

```
[Unit]Description=robotAfter=network.target [Service]Type=forkingExecStart=/usr/local/python3/bin/ENV/bin/python /usr/local/python3/bin/ENV/p3.py &PrivateTmp=true [Install]WantedBy=multi-user.target
```

ExecStart为服务启动时执行的命令，不能用相对路径， 一定要全路径。
这里也可以将命令写到任意的.sh文件中，这里写.sh文件的全路径也是可以的。

(2).启用自定义系统服务

```
systemctl enable robot
```

(3).启动服务

```
systemctl start robot
```

可以查看进程，确认一下服务是否启动

```
ps aux|grep robot
```

 

完毕！

学习时的痛苦是暂时的 未学到的痛苦是终生的





# postgresql

## 1 Linux安装(docker)

### 一、拉取Postgresq镜像

```powershell
docker pull postgres
```

### 二、构建镜像容器

```powershell
docker run -it --name postgres --restart always -e POSTGRES_PASSWORD='123456' -e ALLOW_IP_RANGE=0.0.0.0/0 -v /export/postgresql/data:/var/lib/postgresql -p 55433:5432 -d postgres
```

–name : 自定义容器名称
POSTGRES_PASSWORD：数据库密码
-e ALLOW_IP_RANGE=0.0.0.0/0，这个表示允许所有ip访问，如果不加，则非本机 ip 访问不了
-v :进行映射,本地目录：容器内路径
-p：映射端口,宿主机端口：容器端口
最后是 镜像名称:端口号

### 三、进入postgres容器

```powershell
docker exec -it postgres bash
```

### 四、切换当前用户，再登录数据库

将当前root切换成postgres

```powershell
su postgres
```

输入用户名，密码再命令执行完后，再根据提示输入

```powershell
psql -U postgres -W
```

输入密码，登录成功

### 五、设置远程访问许可（很重要）

共需要修改两个配置文件：pg_hba.conf、postgresql.conf，步骤分别如下：

#### 1、修改postgres配置文件

首先，确认已进入容器，再按下列步骤操作：

##### 1）、修改pg_hba.conf文件

A、用命令将postgres中的pg_hba.conf文件，复制到目录/home中

```powershell
docker cp postgres:/var/lib/postgresql/data/pg_hba.conf /export/postgresql
```

B、用Xftp连接服务器，找到home下的pg_hba.conf，并用记事本打开及修改用户的访问权限（#开头的行是注释内容）：

```yaml
# TYPE DATABASE  USER    CIDR-ADDRESS     METHOD
 # "local" is for Unix domain socket connections only
 local all    all               trust
 # IPv4 local connections:
 host  all    all    127.0.0.1/32     trust
 *host  all    all    0.0.0.1/0    md5*
 # IPv6 local connections:
 host  all    all    ::1/128       trust
12345678
```

C、用命令将修改后的文件，替换掉原来的配置文件

```powershell
docker cp /export/postgresql/pg_hba.conf postgres:/var/lib/postgresql/data
```

##### 2）、修改postgresql.conf文件

如上述修改pg_hba.conf一样，先复件到/home文件夹中，然后打开编辑，最后替换掉原配置文件。
定位到 #listen_addresses = ’localhost’，再将行开头都#去掉，并将行内容修改为 localhost 改成：*

```powershell
listen_addresses = ’*’
```

默认只接受来自本机localhost的连接请求，* 允许数据库服务器监听来自任何主机的连接请求。

#### 2、设置防火墙

首先，执行exit命令，退出postgres用户，再执行一次exit，退出容器。然后才可以进行防火墙设置。

##### 1）、检查 firewalld 启动状态

```powershell
systemctl status firewalld
若未启动，则执行启动命令：
```

```powershell
systemctl start firewalld
```

##### 2）、检查 firewall-cmd 运行状态

```powershell
firewall-cmd --state
```

##### 3）、防火墙正常，则分别执行以下命令，进行配置

```powershell
firewall-cmd --zone=public --add-port=5432/tcp --permanent
firewall-cmd --reload
重启防火墙
```

```powershell
systemctl stop firewalld.service
systemctl start firewalld.service
```

##### 4）、navicat登录端口  55432